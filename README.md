# [Deep-RL-Bootcamp](https://sites.google.com/view/deep-rl-bootcamp)
26-27 August 2017   |   Berkeley CA

The bootcamp covers the following topics:

    RL Basics 
    Policy Gradients 
    Actor-Critic Algorithms 
    Q-learning 
    Evolution Strategies
    RL trouble-shooting and debugging strategies
    Current research frontiers

There will be tutorials sessions for all topics, followed by hands-on lab sessions using OpenAI Gym. 

â€‹Learning Goals

    Understanding the foundations
    Ability to implement state-of-the-art methods from scratch
    Ability to build advanced applications on top of rllab
    Ability to apply Deep RL to new domains


### Labs

* [Prelab](Labs/prelab): Set up your computer for all labs.
* [Lab 1](Labs/lab1): Markov Decision Processes. You will implement value iteration, policy iteration, and tabular Q-learning and apply these algorithms to simple environments including tabular maze navigation (FrozenLake) and controlling a simple crawler robot.
* [Lab 2](Labs/lab2): Introduction to Chainer. You will implement deep supervised learning using Chainer, and apply it to the MNIST dataset.
* [Lab 3](Labs/lab3): Deep Q-Learning. You will implement the DQN algorithm and apply it to Atari games.
* [Lab 4](Labs/lab4): Policy Optimization Algorithms. You will implement various policy optimization algorithms, including policy gradient, natural policy gradient, trust-region policy optimization (TRPO), and asynchronous advantage actor-critic (A3C). You will apply these algorithms to classic control tasks, Atari games, and roboschool locomotion environments.
